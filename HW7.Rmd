---
title: "HW7"
author: "Carol, JOYCE, Mei, Tami"
date: "11/16/2020"
output: github
---

```
```
```{r}
load("/Users/new/Desktop/ecob2000_leture1/NHIS_2014/NHIS_2014.RData")
attach(data_use1)
```

```{r}
data_use1$earn_lastyr <- as.factor(data_use1$ERNYR_P)
levels(data_use1$earn_lastyr) <- c("0","$01-$4999","$5000-$9999","$10000-$14999","$15000-$19999","$20000-$24999","$25000-$34999","$35000-$44999","$45000-$54999","$55000-$64999","$65000-$74999","$75000 and over",NA,NA,NA)
```

##Narrow down the subset between age 21 to 75.
```{r}
dat_2<-subset(data_use1, ((AGE_P>=21)&(AGE_P<=75)))
```

## model_logit1: 
```{r}
model_logit1 <- glm(NOTCOV ~ AGE_P + I(AGE_P^2) + female + Hispanic + Asian +  educ_hs + educ_smcoll + educ_as + educ_bach + educ_adv + married + divorc_sep + REGION, family = binomial, data = dat_2)
```

```{r}
summary(model_logit1)
exp(model_logit1$coefficients)
plot(coef(model_logit1))
```
Interpretation:
1. The variable "divorc_sep" is statistically insignificant.

2.Now we are analyzing variables that affect people not being covered(NOTCOV). To figure out which subset of people are more likely to have an insurance, we interpret the sign of coefficient reversely. People who are female is more likely to get covered. Educational level and getting insured are positively related. When looking at the marriage status, those get married and divorc_sep are more likely to have an insurance than others. 

3.Probability of not getting covered. (exp(model_logit1$coefficients))

REGION: the coefficient of REGIONMidwest is 1.24213288 , (p/(1-p)=1.24213288 ). We got the probability of people in the midwest not geting insured is 55.35%.
We got P(REGIONSouth)=64.08%, P(  REGIONWest)=55.27%. As a result, we concluded that people in the West are less likely to have an insurance.


## Now compare the logit model with probit.
```{r}
model_probit1 <- glm(NOTCOV ~ AGE_P + I(AGE_P^2) + female + Hispanic + Asian +  educ_hs + educ_smcoll + educ_as + educ_bach + educ_adv + married + divorc_sep + REGION, family = binomial(link="probit"), data = dat_2)
summary(model_probit1)
exp(model_probit1$coefficients)
```
Conclusion: the coefficients signs of Logit model and Probit model are the same. Both models demonstrate that "divorc_sep" is insignificant.


#using codes from lab
```{r}
d_region <- data.frame(model.matrix(~ data_use1$REGION))
d_region_born <- data.frame(model.matrix(~ factor(data_use1$region_born)))  # snips any with zero in the subgroup
dat_for_analysis_sub <- data.frame(
  data_use1$NOTCOV,
  data_use1$AGE_P,
  data_use1$female,
  data_use1$AfAm,
  data_use1$Asian,
  data_use1$RaceOther,
  data_use1$Hispanic,
  data_use1$educ_hs,
  data_use1$educ_smcoll,
  data_use1$educ_as,
  data_use1$educ_bach,
  data_use1$educ_adv,
  data_use1$married,
  data_use1$widowed,
  data_use1$divorc_sep,
  d_region[,2:4],
  d_region_born[,2:12]) # need [] since model.matrix includes intercept term

names(dat_for_analysis_sub) <- c("NOTCOV",
                                 "Age",
                                 "female",
                                 "AfAm",
                                 "Asian",
                                 "RaceOther",
                                 "Hispanic",
                                 "educ_hs",
                                 "educ_smcoll",
                                 "educ_as",
                                 "educ_bach",
                                 "educ_adv",
                                 "married",
                                 "widowed",
                                 "divorc_sep",
                                 "Region.Midwest",
                                 "Region.South",
                                 "Region.West",
                                 "born.Mex.CentAm.Carib",
                                 "born.S.Am",
                                 "born.Eur",
                                 "born.f.USSR",
                                 "born.Africa",
                                 "born.MidE",
                                 "born.India.subc",
                                 "born.Asia",
                                 "born.SE.Asia",
                                 "born.elsewhere",
                                 "born.unknown")


```

```{r}
require("standardize")
set.seed(654321)
NN <- length(dat_for_analysis_sub$NOTCOV)
# restrict_1 <- as.logical(round(runif(NN,min=0,max=0.6))) # use fraction as training data
restrict_1 <- (runif(NN) < 0.1) # use 10% as training data
summary(restrict_1)
dat_train <- subset(dat_for_analysis_sub, restrict_1)
dat_test <- subset(dat_for_analysis_sub, !restrict_1)
sobj <- standardize(NOTCOV ~ Age + female + AfAm + Asian + RaceOther + Hispanic + 
                      educ_hs + educ_smcoll + educ_as + educ_bach + educ_adv + 
                      married + widowed + divorc_sep + 
                      Region.Midwest + Region.South + Region.West + 
                      born.Mex.CentAm.Carib + born.S.Am + born.Eur + born.f.USSR + 
                      born.Africa + born.MidE + born.India.subc + born.Asia + 
                      born.SE.Asia + born.elsewhere + born.unknown, dat_train, family = binomial)

s_dat_test <- predict(sobj, dat_test)
```


## Logit model
```{r}
model_logit1 <- glm(sobj$formula, family = binomial, data = sobj$data)
summary(model_logit1)
pred_vals <- predict(model_logit1, s_dat_test, type = "response")
pred_model_logit1 <- (pred_vals > 0.6)
table(pred = pred_model_logit1, true = dat_test$NOTCOV)


```
The logit model gives a result of 
predicted 0, actual 0: 0.375%; 
predicted 0, actual 1: 0.41%; 
predicted 1, actual 0: 87.3%ï¼›
predicted 1, actual 1: 11.9%. 
The model mis-classifies 87.71% of the data.

## randomforest model
```{r}
require('randomForest')
set.seed(54321)
model_randFor <- randomForest(as.factor(NOTCOV) ~ ., data = sobj$data, importance=TRUE, proximity=TRUE)
print(model_randFor)
round(importance(model_randFor),2)
varImpPlot(model_randFor)
# look at confusion matrix for this too
pred_model1 <- predict(model_randFor,  s_dat_test)
table(pred = pred_model1, true = dat_test$NOTCOV)
```
The Randomforest model gives an accuracy of 88.32%.



```{r}
require(e1071)
# tuned_parameters <- tune.svm(as.factor(NOTCOV) ~ ., data = sobj$data, gamma = 10^(-3:0), cost = 10^(-2:1)) 
# summary(tuned_parameters)
# figure best parameters and input into next
svm.model <- svm(as.factor(NOTCOV) ~ ., data = sobj$data, cost = 10, gamma = 0.1)
svm.pred <- predict(svm.model, s_dat_test)
table(pred = svm.pred, true = dat_test$NOTCOV)
```
## the SVM (support vector machines)
The SVM model gives a 87.79% accuracy rate to the model prediction. 




```{r}
# Elastic Net
require(glmnet)
model1_elasticnet <-  glmnet(as.matrix(sobj$data[,-1]),sobj$data$NOTCOV, standardize = T) 
# default is alpha = 1, lasso

par(mar=c(4.5,4.5,1,4))
plot(model1_elasticnet)
vnat=coef(model1_elasticnet)
vnat=vnat[-1,ncol(vnat)] # remove the intercept, and get the coefficients at the end of the path
axis(4, at=vnat,line=-.5,label=names(sobj$data[,-1]),las=1,tick=FALSE, cex.axis=0.5) 

plot(model1_elasticnet, xvar = "lambda")
plot(model1_elasticnet, xvar = "dev", label = TRUE)
print(model1_elasticnet)

cvmodel1_elasticnet = cv.glmnet(data.matrix(sobj$data[,-1]),data.matrix(sobj$data$NOTCOV)) 
cvmodel1_elasticnet$lambda.min
log(cvmodel1_elasticnet$lambda.min)
coef(cvmodel1_elasticnet, s = "lambda.min")

pred1_elasnet <- predict(model1_elasticnet, newx = data.matrix(s_dat_test), s = cvmodel1_elasticnet$lambda.min)
pred_model1_elasnet <- (pred1_elasnet < mean(pred1_elasnet)) 
table(pred = pred_model1_elasnet, true = dat_test$NOTCOV)

model2_elasticnet <-  glmnet(as.matrix(sobj$data[,-1]),sobj$data$NOTCOV, alpha = 0) 
# or try different alpha values to see if you can improve
```
##LASSO model
1.This model gives a 65.5999% accuracy. 
2.% Dev represents the ratio of residual that can be explained by the model. The more it is closer to 1, the better. When Lambda become smaller, more variables are included into the model the higher the %Dev.Since the glmnet () can smartly stop testing when the marginal change of % Dev become smaller and stable. Then we considered the model performs the best. In the model above, when 28 variables are included into the model, lambda approaches 0.0004, we get a kind of satisfying model.


##Change alpha to 0.5(from ridge to elastic net)
```{r}
pred1_elasnet <- predict(model1_elasticnet, newx = data.matrix(s_dat_test), s = cvmodel1_elasticnet$lambda.min)
pred_model1_elasnet <- (pred1_elasnet < mean(pred1_elasnet)) 
table(pred = pred_model1_elasnet, true = dat_test$NOTCOV)

model2_elasticnet <-  glmnet(as.matrix(sobj$data[,-1]),sobj$data$NOTCOV, alpha = 0.5) 
```
When alpha=0.5, the Elastic Net has similar function as LASSO.

